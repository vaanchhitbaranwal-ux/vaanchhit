{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaanchhitbaranwal-ux/vaanchhit/blob/main/GPT4_Research_agents_through_LangGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install graphviz libgraphviz-dev pkg-config"
      ],
      "metadata": {
        "id": "V0fcvFoFAEu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \\\n",
        "    datasets==2.19.1 \\\n",
        "    langchain-pinecone==0.1.1 \\\n",
        "    langchain-openai==0.1.9 \\\n",
        "    langchain==0.2.5 \\\n",
        "    langchain-core==0.2.9 \\\n",
        "    langgraph==0.1.1 \\\n",
        "    semantic-router==0.0.48 \\\n",
        "    serpapi==0.1.5 \\\n",
        "    google-search-results==2.4.2 \\\n",
        "    pygraphviz==1.12"
      ],
      "metadata": {
        "id": "NyVeOTOvAE91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jamescalam/ai-arxiv2-semantic-chunks\", split=\"train\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "lMOpuyIpAqKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "M-Z7eX0JAxH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from semantic_router.encoders import OpenAIEncoder\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or getpass(\"OpenAI API key: \")\n",
        "\n",
        "encoder = OpenAIEncoder(name=\"text-embedding-3-small\")"
      ],
      "metadata": {
        "id": "ltvbkrIhA2WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
        "api_key = os.getenv(\"PINECONE_API_KEY\") or getpass(\"Pinecone API key: \")\n",
        "\n",
        "# configure client\n",
        "pc = Pinecone(api_key=api_key)"
      ],
      "metadata": {
        "id": "g7xjUPkZA-Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "spec = ServerlessSpec(\n",
        "    cloud=\"aws\", region=\"us-west-2\"  # us-east-1\n",
        ")"
      ],
      "metadata": {
        "id": "QnF6DYWxBILQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dims = len(encoder([\"some random text\"])[0])\n",
        "dims"
      ],
      "metadata": {
        "id": "Y7NwWsKeBML1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "\n",
        "index_name = \"gpt-4o-research-agent\"\n",
        "\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    # if does not exist, create index\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=dims,  # dimensionality of embed 3\n",
        "        metric='dotproduct',\n",
        "        spec=spec\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    while not pc.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "time.sleep(1)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ],
      "metadata": {
        "id": "X7gMVV1DBOjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# easier to work with dataset as pandas dataframe\n",
        "data = dataset.to_pandas().iloc[:10000]\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "for i in tqdm(range(0, len(data), batch_size)):\n",
        "    i_end = min(len(data), i+batch_size)\n",
        "    batch = data[i:i_end].to_dict(orient=\"records\")\n",
        "    # get batch of data\n",
        "    metadata = [{\n",
        "        \"title\": r[\"title\"],\n",
        "        \"content\": r[\"content\"],\n",
        "        \"arxiv_id\": r[\"arxiv_id\"],\n",
        "        \"references\": r[\"references\"].tolist()\n",
        "    } for r in batch]\n",
        "    # generate unique ids for each chunk\n",
        "    ids = [r[\"id\"] for r in batch]\n",
        "    # get text content to embed\n",
        "    content = [r[\"content\"] for r in batch]\n",
        "    # embed text\n",
        "    embeds = encoder(content)\n",
        "    # add to Pinecone\n",
        "    index.upsert(vectors=zip(ids, embeds, metadata))"
      ],
      "metadata": {
        "id": "jUuiPeS7BUFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, List, Union\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "from langchain_core.messages import BaseMessage\n",
        "import operator\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    input: str\n",
        "    chat_history: list[BaseMessage]\n",
        "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
      ],
      "metadata": {
        "id": "OuZKQ0gOBdsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# we will test with the mixtral paper\n",
        "arxiv_id = \"2401.04088\"\n",
        "\n",
        "res = requests.get(\n",
        "    f\"https://export.arxiv.org/abs/{arxiv_id}\"\n",
        ")\n",
        "res.text"
      ],
      "metadata": {
        "id": "w2FwiGaDBoGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# our regex\n",
        "abstract_pattern = re.compile(\n",
        "    r'\\s*Abstract:\\s*(.*?)\\s*',\n",
        "    re.DOTALL\n",
        ")\n",
        "\n",
        "# we search\n",
        "re_match = abstract_pattern.search(res.text)\n",
        "\n",
        "# and now let's see what we got\n",
        "print(re_match.group(1))"
      ],
      "metadata": {
        "id": "YTLfEeZoB1vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool(\"fetch_arxiv\")\n",
        "def fetch_arxiv(arxiv_id: str):\n",
        "    \"\"\"Gets the abstract from an ArXiv paper given the arxiv ID. Useful for\n",
        "    finding high-level context about a specific paper.\"\"\"\n",
        "    # get paper page in html\n",
        "    res = requests.get(\n",
        "        f\"https://export.arxiv.org/abs/{arxiv_id}\"\n",
        "    )\n",
        "    # search html for abstract\n",
        "    re_match = abstract_pattern.search(res.text)\n",
        "    # return abstract text\n",
        "    return re_match.group(1)"
      ],
      "metadata": {
        "id": "6m16a5EfCaKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    fetch_arxiv.invoke(input={\"arxiv_id\": arxiv_id})\n",
        ")"
      ],
      "metadata": {
        "id": "nPGH72nNCmGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from serpapi import GoogleSearch\n",
        "\n",
        "serpapi_params = {\n",
        "    \"engine\": \"google\",\n",
        "    \"api_key\": os.getenv(\"SERPAPI_KEY\") or getpass(\"SerpAPI key: \")\n",
        "}\n",
        "\n",
        "search = GoogleSearch({\n",
        "    **serpapi_params,\n",
        "    \"q\": \"coffee\"\n",
        "})\n",
        "\n",
        "results = search.get_dict()[\"organic_results\"]"
      ],
      "metadata": {
        "id": "0ZnMexujCsz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexts = \"\\n---\\n\".join(\n",
        "    [\"\\n\".join([x[\"title\"], x[\"snippet\"], x[\"link\"]]) for x in results]\n",
        ")"
      ],
      "metadata": {
        "id": "5-jqHoYYC1fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(contexts)"
      ],
      "metadata": {
        "id": "IjcVsQv0C3Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool(\"web_search\")\n",
        "def web_search(query: str):\n",
        "    \"\"\"Finds general knowledge information using Google search. Can also be used\n",
        "    to augment more 'general' knowledge to a previous specialist query.\"\"\"\n",
        "    search = GoogleSearch({\n",
        "        **serpapi_params,\n",
        "        \"q\": query,\n",
        "        \"num\": 5\n",
        "    })\n",
        "    results = search.get_dict()[\"organic_results\"]\n",
        "    contexts = \"\\n---\\n\".join(\n",
        "        [\"\\n\".join([x[\"title\"], x[\"snippet\"], x[\"link\"]]) for x in results]\n",
        "    )\n",
        "    return contexts"
      ],
      "metadata": {
        "id": "gVoI3yoCC69A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "def format_rag_contexts(matches: list):\n",
        "    contexts = []\n",
        "    for x in matches:\n",
        "        text = (\n",
        "            f\"Title: {x['metadata']['title']}\\n\"\n",
        "            f\"Content: {x['metadata']['content']}\\n\"\n",
        "            f\"ArXiv ID: {x['metadata']['arxiv_id']}\\n\"\n",
        "            f\"Related Papers: {x['metadata']['references']}\\n\"\n",
        "        )\n",
        "        contexts.append(text)\n",
        "    context_str = \"\\n---\\n\".join(contexts)\n",
        "    return context_str\n",
        "\n",
        "@tool(\"rag_search_filter\")\n",
        "def rag_search_filter(query: str, arxiv_id: str):\n",
        "    \"\"\"Finds information from our ArXiv database using a natural language query\n",
        "    and a specific ArXiv ID. Allows us to learn more details about a specific paper.\"\"\"\n",
        "    xq = encoder([query])\n",
        "    xc = index.query(vector=xq, top_k=6, include_metadata=True, filter={\"arxiv_id\": arxiv_id})\n",
        "    context_str = format_rag_contexts(xc[\"matches\"])\n",
        "    return context_str\n",
        "\n",
        "@tool(\"rag_search\")\n",
        "def rag_search(query: str):\n",
        "    \"\"\"Finds specialist information on AI using a natural language query.\"\"\"\n",
        "    xq = encoder([query])\n",
        "    xc = index.query(vector=xq, top_k=2, include_metadata=True)\n",
        "    context_str = format_rag_contexts(xc[\"matches\"])\n",
        "    return context_str"
      ],
      "metadata": {
        "id": "bIiwBOv1DPKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool(\"final_answer\")\n",
        "def final_answer(\n",
        "    introduction: str,\n",
        "    research_steps: str,\n",
        "    main_body: str,\n",
        "    conclusion: str,\n",
        "    sources: str\n",
        "):\n",
        "    \"\"\"Returns a natural language response to the user in the form of a research\n",
        "    report. There are several sections to this report, those are:\n",
        "    - `introduction`: a short paragraph introducing the user's question and the\n",
        "    topic we are researching.\n",
        "    - `research_steps`: a few bullet points explaining the steps that were taken\n",
        "    to research your report.\n",
        "    - `main_body`: this is where the bulk of high quality and concise\n",
        "    information that answers the user's question belongs. It is 3-4 paragraphs\n",
        "    long in length.\n",
        "    - `conclusion`: this is a short single paragraph conclusion providing a\n",
        "    concise but sophisticated view on what was found.\n",
        "    - `sources`: a bulletpoint list provided detailed sources for all information\n",
        "    referenced during the research process\n",
        "    \"\"\"\n",
        "    if type(research_steps) is list:\n",
        "        research_steps = \"\\n\".join([f\"- {r}\" for r in research_steps])\n",
        "    if type(sources) is list:\n",
        "        sources = \"\\n\".join([f\"- {s}\" for s in sources])\n",
        "    return \"\""
      ],
      "metadata": {
        "id": "KAF-8TVqDqQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "system_prompt = \"\"\"You are the oracle, the great AI decision maker.\n",
        "Given the user's query you must decide what to do with it based on the\n",
        "list of tools provided to you.\n",
        "\n",
        "If you see that a tool has been used (in the scratchpad) with a particular\n",
        "query, do NOT use that same tool with the same query again. Also, do NOT use\n",
        "any tool more than twice (ie, if the tool appears in the scratchpad twice, do\n",
        "not use it again).\n",
        "\n",
        "You should aim to collect information from a diverse range of sources before\n",
        "providing the answer to the user. Once you have collected plenty of information\n",
        "to answer the user's question (stored in the scratchpad) use the final_answer\n",
        "tool.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"assistant\", \"scratchpad: {scratchpad}\"),\n",
        "])"
      ],
      "metadata": {
        "id": "gXuBDegyDwzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_core.messages import ToolCall, ToolMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o\",\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "tools=[\n",
        "    rag_search_filter,\n",
        "    rag_search,\n",
        "    fetch_arxiv,\n",
        "    web_search,\n",
        "    final_answer\n",
        "]\n",
        "\n",
        "# define a function to transform intermediate_steps from list\n",
        "# of AgentAction to scratchpad string\n",
        "def create_scratchpad(intermediate_steps: list[AgentAction]):\n",
        "    research_steps = []\n",
        "    for i, action in enumerate(intermediate_steps):\n",
        "        if action.log != \"TBD\":\n",
        "            # this was the ToolExecution\n",
        "            research_steps.append(\n",
        "                f\"Tool: {action.tool}, input: {action.tool_input}\\n\"\n",
        "                f\"Output: {action.log}\"\n",
        "            )\n",
        "    return \"\\n---\\n\".join(research_steps)\n",
        "\n",
        "oracle = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "        \"scratchpad\": lambda x: create_scratchpad(\n",
        "            intermediate_steps=x[\"intermediate_steps\"]\n",
        "        ),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
        ")"
      ],
      "metadata": {
        "id": "6IhSWhBLD2DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"input\": \"tell me something interesting about dogs\",\n",
        "    \"chat_history\": [],\n",
        "    \"intermediate_steps\": [],\n",
        "}\n",
        "out = oracle.invoke(inputs)\n",
        "out"
      ],
      "metadata": {
        "id": "fEih54gUD7GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.tool_calls[0][\"name\"]"
      ],
      "metadata": {
        "id": "CUkBGDrND_Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.tool_calls[0][\"args\"]"
      ],
      "metadata": {
        "id": "0SmGRbhBECp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def run_oracle(state: list):\n",
        "    print(\"run_oracle\")\n",
        "    print(f\"intermediate_steps: {state['intermediate_steps']}\")\n",
        "    out = oracle.invoke(state)\n",
        "    tool_name = out.tool_calls[0][\"name\"]\n",
        "    tool_args = out.tool_calls[0][\"args\"]\n",
        "    action_out = AgentAction(\n",
        "        tool=tool_name,\n",
        "        tool_input=tool_args,\n",
        "        log=\"TBD\"\n",
        "    )\n",
        "    return {\n",
        "        \"intermediate_steps\": [action_out]\n",
        "    }\n",
        "\n",
        "def router(state: list):\n",
        "    # return the tool name to use\n",
        "    if isinstance(state[\"intermediate_steps\"], list):\n",
        "        return state[\"intermediate_steps\"][-1].tool\n",
        "    else:\n",
        "        # if we output bad format go to final answer\n",
        "        print(\"Router invalid format\")\n",
        "        return \"final_answer\""
      ],
      "metadata": {
        "id": "9SsUc72zEFid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tool_str_to_func = {\n",
        "    \"rag_search_filter\": rag_search_filter,\n",
        "    \"rag_search\": rag_search,\n",
        "    \"fetch_arxiv\": fetch_arxiv,\n",
        "    \"web_search\": web_search,\n",
        "    \"final_answer\": final_answer\n",
        "}\n",
        "\n",
        "def run_tool(state: list):\n",
        "    # use this as helper function so we repeat less code\n",
        "    tool_name = state[\"intermediate_steps\"][-1].tool\n",
        "    tool_args = state[\"intermediate_steps\"][-1].tool_input\n",
        "    print(f\"{tool_name}.invoke(input={tool_args})\")\n",
        "    # run tool\n",
        "    out = tool_str_to_func[tool_name].invoke(input=tool_args)\n",
        "    action_out = AgentAction(\n",
        "        tool=tool_name,\n",
        "        tool_input=tool_args,\n",
        "        log=str(out)\n",
        "    )\n",
        "    return {\"intermediate_steps\": [action_out]}"
      ],
      "metadata": {
        "id": "tAgpqgvzEVbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "\n",
        "graph.add_node(\"oracle\", run_oracle)\n",
        "graph.add_node(\"rag_search_filter\", run_tool)\n",
        "graph.add_node(\"rag_search\", run_tool)\n",
        "graph.add_node(\"fetch_arxiv\", run_tool)\n",
        "graph.add_node(\"web_search\", run_tool)\n",
        "graph.add_node(\"final_answer\", run_tool)\n",
        "\n",
        "graph.set_entry_point(\"oracle\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    source=\"oracle\",  # where in graph to start\n",
        "    path=router,  # function to determine which node is called\n",
        ")\n",
        "\n",
        "# create edges from each tool back to the oracle\n",
        "for tool_obj in tools:\n",
        "    if tool_obj.name != \"final_answer\":\n",
        "        graph.add_edge(tool_obj.name, \"oracle\")\n",
        "\n",
        "# if anything goes to final answer, it must then move to END\n",
        "graph.add_edge(\"final_answer\", END)\n",
        "\n",
        "runnable = graph.compile()"
      ],
      "metadata": {
        "id": "PQ83gDhgEc00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(runnable.get_graph().draw_png())"
      ],
      "metadata": {
        "id": "HeCoDq1eEmjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = runnable.invoke({\n",
        "    \"input\": \"tell me something interesting about dogs\",\n",
        "    \"chat_history\": [],\n",
        "})"
      ],
      "metadata": {
        "id": "nbbaYzDUEpit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_report(output: dict):\n",
        "    research_steps = output[\"research_steps\"]\n",
        "    if type(research_steps) is list:\n",
        "        research_steps = \"\\n\".join([f\"- {r}\" for r in research_steps])\n",
        "    sources = output[\"sources\"]\n",
        "    if type(sources) is list:\n",
        "        sources = \"\\n\".join([f\"- {s}\" for s in sources])\n",
        "    return f\"\"\""
      ],
      "metadata": {
        "id": "JsnPdzOeEusS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(build_report(\n",
        "    output=out[\"intermediate_steps\"][-1].tool_input\n",
        "))"
      ],
      "metadata": {
        "id": "Kx63zMdLE4dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = runnable.invoke({\n",
        "    \"input\": \"tell me about AI\",\n",
        "    \"chat_history\": []\n",
        "})"
      ],
      "metadata": {
        "id": "ulY_1JEGFAbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(build_report(\n",
        "    output=out[\"intermediate_steps\"][-1].tool_input\n",
        "))"
      ],
      "metadata": {
        "id": "9YZTr7VoFFp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = runnable.invoke({\n",
        "    \"input\": \"what is retrieval augmented generation?\",\n",
        "    \"chat_history\": []\n",
        "})"
      ],
      "metadata": {
        "id": "Mp1VLjYuFJ-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(build_report(\n",
        "    output=out[\"intermediate_steps\"][-1].tool_input\n",
        "))"
      ],
      "metadata": {
        "id": "A457QpYCFMon"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}