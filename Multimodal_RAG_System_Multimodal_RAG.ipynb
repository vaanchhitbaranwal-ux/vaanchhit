{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaanchhitbaranwal-ux/vaanchhit/blob/main/Multimodal_RAG_System_Multimodal_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import streamlit as st\n",
        "\n",
        "from src.ollama_chain import OllamaChain, OllamaRAGChain\n",
        "from src.llama_cpp_chains import LlamaChain\n",
        "from src.pdf_handler import extract_pdf\n",
        "from src.vqa import answer_visual_question\n",
        "from src.audio_processor import AudioProcessor\n",
        "from langchain_community.chat_message_histories import StreamlitChatMessageHistory\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "audio_processor = AudioProcessor()\n",
        "\n",
        "@st.cache_resource\n",
        "def load_chain(_chat_memory):\n",
        "    if st.session_state.pdf_chat:\n",
        "        return OllamaRAGChain(_chat_memory)\n",
        "    else:\n",
        "        return OllamaChain(_chat_memory)\n",
        "\n",
        "\n",
        "def file_uploader_change():\n",
        "    if st.session_state.uploaded_file:\n",
        "        if not st.session_state.pdf_chat:\n",
        "            clear_cache()\n",
        "            st.session_state.pdf_chat = True\n",
        "\n",
        "        st.session_state.knowledge_change = True\n",
        "\n",
        "    else:\n",
        "        clear_cache()\n",
        "        st.session_state.pdf_chat = False\n",
        "\n",
        "\n",
        "def toggle_pdf_chat_change():\n",
        "    clear_cache()\n",
        "    if st.session_state.pdf_chat and st.session_state.uploaded_file:\n",
        "        st.session_state.knowledge_change = True\n",
        "\n",
        "\n",
        "def clear_input_field():\n",
        "    # store the question\n",
        "    st.session_state.user_question = st.session_state.user_input\n",
        "    # clear the variable\n",
        "    st.session_state.user_input = \"\"\n",
        "\n",
        "\n",
        "def set_send_input():\n",
        "    st.session_state.send_input = True\n",
        "    clear_input_field()\n",
        "\n",
        "\n",
        "def clear_cache():\n",
        "    st.cache_resource.clear()\n",
        "\n",
        "\n",
        "def initial_session_state():\n",
        "    st.session_state.send_input = False\n",
        "    st.session_state.knowledge_change = False\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Initialize\n",
        "    # Title\n",
        "    st.title('OVERKILL LLM')\n",
        "    chat_container = st.container()\n",
        "\n",
        "    # sidebar\n",
        "    # st.sidebar.title('Chat Session')\n",
        "\n",
        "    # file upload\n",
        "    st.sidebar.toggle('PDF Chat', value=False, key='pdf_chat', on_change=toggle_pdf_chat_change)\n",
        "    uploaded_pdf = st.sidebar.file_uploader('Upload your pdf files',\n",
        "                                            type='pdf',\n",
        "                                            accept_multiple_files=True,\n",
        "                                            key='uploaded_file',\n",
        "                                            on_change=file_uploader_change)\n",
        "\n",
        "    # Image upload\n",
        "    uploaded_image = st.sidebar.file_uploader('Upload Images', type=['jpg', 'jpeg', 'png'], key='uploaded_image')\n",
        "\n",
        "    # Audio upload\n",
        "    uploaded_audio = st.sidebar.file_uploader('Upload Audio', type=['wav', 'mp3'], key='uploaded_audio')\n",
        "\n",
        "    # Input objects\n",
        "    user_input = st.text_input('Message OVERKILL', key='user_input', on_change=set_send_input)\n",
        "    send_button = st.button('Send', key='send_button')\n",
        "\n",
        "    # Session state\n",
        "    if 'send_input' not in st.session_state:\n",
        "        initial_session_state()\n",
        "    # ----------------------------------------------------------------------------------------------------\n",
        "\n",
        "    chat_history = StreamlitChatMessageHistory(key='history')\n",
        "\n",
        "    with chat_container:\n",
        "        for msg in chat_history.messages:\n",
        "            st.chat_message(msg.type).write(msg.content)\n",
        "\n",
        "    llm_chain = load_chain(chat_history)\n",
        "    if st.session_state.knowledge_change:\n",
        "        with st.spinner('Updating knowledge base'):\n",
        "            llm_chain.update_chain(uploaded_pdf)\n",
        "            st.session_state.knowledge_change = False\n",
        "\n",
        "    # we use \"or\" operation here because user can press 'Enter' instead of 'Send' button\n",
        "    if (send_button or st.session_state.send_input) and st.session_state.user_question != \"\":\n",
        "        with chat_container:\n",
        "            st.chat_message('user').write(st.session_state.user_question)\n",
        "\n",
        "            if uploaded_image:\n",
        "                image_path = os.path.join('./.cache/temp_files', uploaded_image.name)\n",
        "                with open(image_path, 'wb') as f:\n",
        "                    f.write(uploaded_image.getvalue())\n",
        "                llm_response = answer_visual_question(image_path, st.session_state.user_question)\n",
        "            elif uploaded_audio:\n",
        "                audio_path = os.path.join('./.cache/temp_files', uploaded_audio.name)\n",
        "                with open(audio_path, 'wb') as f:\n",
        "                    f.write(uploaded_audio.getvalue())\n",
        "                st.write(f\"Processing audio file: {audio_path}\")  # Debug statement\n",
        "                st.session_state.user_question = audio_processor.audio_to_text(audio_path)\n",
        "                st.write(f\"Converted audio to text: {st.session_state.user_question}\")  # Debug statement\n",
        "                llm_response = llm_chain.run(user_input=st.session_state.user_question)\n",
        "            else:\n",
        "                llm_response = llm_chain.run(user_input=st.session_state.user_question)\n",
        "\n",
        "            st.session_state.user_question = \"\"\n",
        "            st.chat_message('ai').write(llm_response)\n",
        "\n",
        "            # Convert response to speech and play it\n",
        "            audio_file = audio_processor.text_to_speech(llm_response)\n",
        "            audio_bytes = open(audio_file, 'rb').read()\n",
        "            st.audio(audio_bytes, format='audio/mp3')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "uPaD1DmIlQka"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}