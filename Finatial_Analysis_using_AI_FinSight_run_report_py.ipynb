{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaanchhitbaranwal-ux/vaanchhit/blob/main/Finatial_Analysis_using_AI_FinSight_run_report_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import asyncio\n",
        "import traceback\n",
        "from collections import defaultdict\n",
        "import logging\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from src.config import Config\n",
        "from src.agents import DataCollector, DataAnalyzer, ReportGenerator\n",
        "from src.memory import Memory\n",
        "from src.utils import setup_logger\n",
        "from src.utils import get_logger\n",
        "get_logger().set_agent_context('runner', 'main')\n",
        "\n",
        "IF_RESUME = True\n",
        "MAX_CONCURRENT = 3\n",
        "\n",
        "\n",
        "async def run_report(resume: bool = True, max_concurrent: int = None):\n",
        "    \"\"\"\n",
        "    Run report generation with optional concurrency limit.\n",
        "\n",
        "    Args:\n",
        "        resume: Whether to resume from previous state\n",
        "        max_concurrent: Maximum number of concurrent tasks. If None, uses MAX_CONCURRENT env var or unlimited.\n",
        "    \"\"\"\n",
        "    use_llm_name = os.getenv(\"DS_MODEL_NAME\")\n",
        "    use_vlm_name = os.getenv(\"VLM_MODEL_NAME\")\n",
        "    use_embedding_name = os.getenv(\"EMBEDDING_MODEL_NAME\")\n",
        "\n",
        "    # Get max concurrent from parameter, env var, or default to unlimited\n",
        "    if max_concurrent is None:\n",
        "        max_concurrent = int(os.getenv(\"MAX_CONCURRENT\", \"0\")) or None\n",
        "    config = Config(\n",
        "        config_file_path='my_config.yaml',\n",
        "        config_dict={}\n",
        "    )\n",
        "    collect_tasks = config.config['custom_collect_tasks']\n",
        "    analysis_tasks = config.config['custom_analysis_tasks']\n",
        "    # Initialize memory\n",
        "    memory = Memory(config=config)\n",
        "\n",
        "    # Initialize logger\n",
        "    log_dir = os.path.join(config.working_dir, 'logs')\n",
        "    logger = setup_logger(log_dir=log_dir, log_level=logging.INFO)\n",
        "\n",
        "    # Log concurrency settings\n",
        "    if max_concurrent:\n",
        "        logger.info(f\"Concurrency limit: {max_concurrent} tasks\")\n",
        "    else:\n",
        "        logger.info(\"No concurrency limit (unlimited)\")\n",
        "\n",
        "    if resume:\n",
        "        memory.load()\n",
        "        logger.info(\"Memory state loaded\")\n",
        "\n",
        "    # Generate additional collect and analysis tasks using LLM if not already generated\n",
        "    research_query = f\"Research target: {config.config['target_name']} (ticker: {config.config['stock_code']}), target type: {config.config.get('target_type', 'company')}\"\n",
        "\n",
        "    # Generate collect tasks if not already generated (or if we want fresh tasks)\n",
        "    if not memory.generated_collect_tasks:\n",
        "        logger.info(\"Generating collect tasks using LLM...\")\n",
        "        generated_collect_tasks = await memory.generate_collect_tasks(\n",
        "            query=research_query,\n",
        "            use_llm_name=use_llm_name,\n",
        "            max_num=5,\n",
        "            existing_tasks=collect_tasks  # Pass existing tasks to avoid duplication\n",
        "        )\n",
        "        logger.info(f\"Generated {len(generated_collect_tasks)} collect tasks\")\n",
        "    else:\n",
        "        generated_collect_tasks = memory.generated_collect_tasks\n",
        "        logger.info(f\"Using {len(generated_collect_tasks)} previously generated collect tasks\")\n",
        "\n",
        "    # Generate analysis tasks if not already generated\n",
        "    if not memory.generated_analysis_tasks:\n",
        "        logger.info(\"Generating analysis tasks using LLM...\")\n",
        "        generated_analysis_tasks = await memory.generate_analyze_tasks(\n",
        "            query=research_query,\n",
        "            use_llm_name=use_llm_name,\n",
        "            max_num=5,\n",
        "            existing_tasks=analysis_tasks  # Pass existing tasks to avoid duplication\n",
        "        )\n",
        "        logger.info(f\"Generated {len(generated_analysis_tasks)} analysis tasks\")\n",
        "    else:\n",
        "        generated_analysis_tasks = memory.generated_analysis_tasks\n",
        "        logger.info(f\"Using {len(generated_analysis_tasks)} previously generated analysis tasks\")\n",
        "\n",
        "    # Merge custom tasks with generated tasks (remove duplicates)\n",
        "    all_collect_tasks = list(collect_tasks) + [task for task in generated_collect_tasks if task not in collect_tasks]\n",
        "    all_analysis_tasks = list(analysis_tasks) + [task for task in generated_analysis_tasks if task not in analysis_tasks]\n",
        "\n",
        "    logger.info(f\"Total collect tasks: {len(all_collect_tasks)} (custom: {len(collect_tasks)}, generated: {len(generated_collect_tasks)})\")\n",
        "    logger.info(f\"Total analysis tasks: {len(all_analysis_tasks)} (custom: {len(analysis_tasks)}, generated: {len(generated_analysis_tasks)})\")\n",
        "\n",
        "    # Update the tasks to be used\n",
        "    collect_tasks = all_collect_tasks\n",
        "    analysis_tasks = all_analysis_tasks\n",
        "    # print(memory.task_mapping)\n",
        "    # mapping = memory.task_mapping\n",
        "    # for item in mapping:\n",
        "    #     print(item['agent_id'])\n",
        "    # assert False\n",
        "\n",
        "    # Prepare prioritized task list (lower value = higher priority)\n",
        "    tasks_to_run = []\n",
        "\n",
        "    # Data-collection tasks\n",
        "    for task in collect_tasks:\n",
        "        tasks_to_run.append({\n",
        "            'agent_class': DataCollector,\n",
        "            'task_input': {\n",
        "                'input_data': {'task': f'Research target: {config.config[\"target_name\"]} (ticker: {config.config[\"stock_code\"]}), task: {task}'},\n",
        "                'echo': True,\n",
        "                'max_iterations': 20,\n",
        "                'resume': resume,\n",
        "            },\n",
        "            'agent_kwargs': {\n",
        "                'use_llm_name': use_llm_name,\n",
        "            },\n",
        "            'priority': 1,\n",
        "        })\n",
        "\n",
        "    # Analysis tasks (run after collection)\n",
        "    for task in analysis_tasks:\n",
        "        tasks_to_run.append({\n",
        "            'agent_class': DataAnalyzer,\n",
        "            'task_input': {\n",
        "                'input_data': {\n",
        "                    'task': f'Research target: {config.config[\"target_name\"]} (ticker: {config.config[\"stock_code\"]})',\n",
        "                    'analysis_task': task\n",
        "                },\n",
        "                'echo': True,\n",
        "                'max_iterations': 20,\n",
        "                'resume': resume,\n",
        "            },\n",
        "            'agent_kwargs': {\n",
        "                'use_llm_name': use_llm_name,\n",
        "                'use_vlm_name': use_vlm_name,\n",
        "                'use_embedding_name': use_embedding_name,\n",
        "            },\n",
        "            'priority': 2,\n",
        "        })\n",
        "\n",
        "    # Report generation task\n",
        "    tasks_to_run.append({\n",
        "        'agent_class': ReportGenerator,\n",
        "        'task_input': {\n",
        "            'input_data': {\n",
        "                'task': f'Research target: {config.config[\"target_name\"]} (ticker: {config.config[\"stock_code\"]})',\n",
        "                'task_type': 'company',\n",
        "            },\n",
        "            'echo': True,\n",
        "            'max_iterations': 20,\n",
        "            'resume': resume,\n",
        "        },\n",
        "        'agent_kwargs': {\n",
        "            'use_llm_name': use_llm_name,\n",
        "            'use_embedding_name': use_embedding_name,\n",
        "        },\n",
        "        'priority': 3,\n",
        "    })\n",
        "\n",
        "\n",
        "    # Use memory to obtain/create the required agents (records tasks internally)\n",
        "    agents_info = []\n",
        "    for task_info in tasks_to_run:\n",
        "        agent = await memory.get_or_create_agent(\n",
        "            agent_class=task_info['agent_class'],\n",
        "            task_input=task_info['task_input'],\n",
        "            resume=resume,\n",
        "            priority=task_info['priority'],\n",
        "            **task_info['agent_kwargs']\n",
        "        )\n",
        "        # Retrieve the persisted priority (may differ on resume)\n",
        "        actual_priority = task_info['priority']\n",
        "        for saved_task in memory.task_mapping:\n",
        "            if saved_task.get('agent_id') == agent.id:\n",
        "                actual_priority = saved_task.get('priority', task_info['priority'])\n",
        "                break\n",
        "\n",
        "        agents_info.append({\n",
        "            'agent': agent,\n",
        "            'task_input': task_info['task_input'],\n",
        "            'priority': actual_priority,\n",
        "        })\n",
        "\n",
        "\n",
        "    memory.save()\n",
        "\n",
        "\n",
        "    # Execute tasks by priority tier (parallel within a tier)\n",
        "    agents_info.sort(key=lambda x: x['priority'])\n",
        "\n",
        "    # Group tasks by priority\n",
        "    priority_groups = defaultdict(list)\n",
        "    for agent_info in agents_info:\n",
        "        priority_groups[agent_info['priority']].append(agent_info)\n",
        "\n",
        "    # Execute each priority tier sequentially\n",
        "    sorted_priorities = sorted(priority_groups.keys())\n",
        "    for priority in sorted_priorities:\n",
        "        group = priority_groups[priority]\n",
        "        agent_resume = group[0]['task_input']['resume']\n",
        "        concurrency_info = f\" (max concurrent: {max_concurrent})\" if max_concurrent else \"\"\n",
        "        logger.info(f\"\\nExecuting priority {priority} group ({len(group)} task(s){concurrency_info})\")\n",
        "\n",
        "        # Skip tasks that already finished\n",
        "        tasks_to_run = []\n",
        "        for agent_info in group:\n",
        "            agent = agent_info['agent']\n",
        "            if agent_resume and resume and memory.is_agent_finished(agent.id):\n",
        "                logger.info(f\"Agent {agent.id} already completed; skip\")\n",
        "                continue\n",
        "            tasks_to_run.append(agent_info)\n",
        "\n",
        "        if not tasks_to_run:\n",
        "            logger.info(f\"All tasks with priority {priority} are complete\")\n",
        "            continue\n",
        "\n",
        "        # Run tasks within the tier with concurrency limit\n",
        "        semaphore = asyncio.Semaphore(max_concurrent) if max_concurrent else None\n",
        "\n",
        "        async def run_agent_with_limit(agent_info):\n",
        "            \"\"\"Run agent with semaphore limit if configured\"\"\"\n",
        "            agent = agent_info['agent']\n",
        "            if semaphore:\n",
        "                async with semaphore:\n",
        "                    logger.info(f\"Starting agent {agent.id}\")\n",
        "                    return await agent.async_run(**agent_info['task_input'])\n",
        "            else:\n",
        "                logger.info(f\"Starting agent {agent.id}\")\n",
        "                return await agent.async_run(**agent_info['task_input'])\n",
        "\n",
        "        # Create tasks\n",
        "        async_tasks = []\n",
        "        for agent_info in tasks_to_run:\n",
        "            async_tasks.append(asyncio.create_task(\n",
        "                run_agent_with_limit(agent_info)\n",
        "            ))\n",
        "\n",
        "        # Wait for completion\n",
        "        if async_tasks:\n",
        "            results = await asyncio.gather(*async_tasks, return_exceptions=True)\n",
        "            for agent_info, result in zip(tasks_to_run, results):\n",
        "                agent = agent_info['agent']\n",
        "                if isinstance(result, Exception):\n",
        "                    # Format full traceback for better debugging\n",
        "                    tb_str = ''.join(traceback.format_exception(type(result), result, result.__traceback__))\n",
        "                    logger.error(f\"  Task failed: Agent {agent.id}, error: {result}\\n{tb_str}\")\n",
        "                else:\n",
        "                    logger.info(f\"  Task finished: Agent {agent.id}\")\n",
        "\n",
        "        logger.info(f\"Priority {priority} group finished\\n\")\n",
        "\n",
        "    # Persist final state\n",
        "    memory.save()\n",
        "    logger.info(\"All tasks completed\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    asyncio.run(run_report(resume=IF_RESUME, max_concurrent=MAX_CONCURRENT))\n"
      ],
      "metadata": {
        "id": "fMqcNBFIaLST"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}