{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaanchhitbaranwal-ux/vaanchhit/blob/main/IT_Support_Analyst_cloud_sentiment_pipeline_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "print(\"Running in Colab:\", IN_COLAB)"
      ],
      "metadata": {
        "id": "65kS1cp6aPLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark gcsfs"
      ],
      "metadata": {
        "id": "xQKHhHfDaU2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "NjpZtLADaYqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Sentiment Analysis\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "qCObJf-taf2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gcsfs\n",
        "\n",
        "bucket_name = \"cis-415-project-jedwardr\"\n",
        "file_name = \"sentiment_small_dataset.csv\"\n",
        "\n",
        "gcs_path = f\"gs://{bucket_name}/{file_name}\"\n",
        "local_path = f\"/content/{file_name}\"\n",
        "\n",
        "# Download file from GCS to local Colab environment\n",
        "fs = gcsfs.GCSFileSystem()\n",
        "with fs.open(gcs_path, 'rb') as f:\n",
        "    with open(local_path, 'wb') as out_file:\n",
        "        out_file.write(f.read())\n",
        "\n",
        "# Load the local CSV file into Spark\n",
        "df = spark.read.csv(local_path, header=True, inferSchema=True)\n",
        "df.show(5)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "bHFly8KYahUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Tokenizer, CountVectorizer, StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression, NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "V43T0LmBapGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "df.describe().show()\n",
        "# Check for missing values\n",
        "df.select([col(c).isNull().alias(c) for c in df.columns]).show()"
      ],
      "metadata": {
        "id": "itiAUzNBaw_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "df = df.na.drop()  # Drop rows with null values\n",
        "df = df.withColumn('Sentiment_Score', col('Sentiment_Score').cast('int'))  # Ensure target is int\n",
        "# Tokenizing the 'Feedback_Text' column\n",
        "tokenizer = Tokenizer(inputCol='Feedback_Text', outputCol='words')\n",
        "# Vectorizing the words column\n",
        "vectorizer = CountVectorizer(inputCol='words', outputCol='features')\n",
        "# Indexing the target variable 'Sentiment_Score'\n",
        "indexer = StringIndexer(inputCol='Sentiment_Score', outputCol='label')"
      ],
      "metadata": {
        "id": "1VCTRBiwazC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Test Split\n",
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
        "train_df.show(5)"
      ],
      "metadata": {
        "id": "x-mndcWqa437"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression Model\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
        "lr_pipeline = Pipeline(stages=[tokenizer, vectorizer, indexer, lr])\n",
        "\n",
        "lr_model = lr_pipeline.fit(train_df)\n",
        "lr_predictions = lr_model.transform(test_df)\n",
        "\n",
        "lr_predictions.select('Feedback_Text', 'Sentiment_Score', 'prediction').show(5)"
      ],
      "metadata": {
        "id": "VLdY6FK7a8le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Naive Bayes Model\n",
        "nb = NaiveBayes(modelType='multinomial', labelCol='label', featuresCol='features')\n",
        "nb_pipeline = Pipeline(stages=[tokenizer, vectorizer, indexer, nb])\n",
        "\n",
        "nb_model = nb_pipeline.fit(train_df)\n",
        "nb_predictions = nb_model.transform(test_df)"
      ],
      "metadata": {
        "id": "rUJlXYtfbGvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation (Accuracy + F1)\n",
        "\n",
        "# Accuracy\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
        "lr_accuracy = evaluator.evaluate(lr_predictions)\n",
        "nb_accuracy = evaluator.evaluate(nb_predictions)\n",
        "\n",
        "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")\n",
        "print(f\"Naive Bayes Accuracy: {nb_accuracy:.4f}\")\n",
        "\n",
        "# F1 Score\n",
        "f1_eval = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='f1')\n",
        "lr_f1 = f1_eval.evaluate(lr_predictions)\n",
        "nb_f1 = f1_eval.evaluate(nb_predictions)\n",
        "\n",
        "print(f\"Logistic Regression F1 Score: {lr_f1:.4f}\")\n",
        "print(f\"Naive Bayes F1 Score: {nb_f1:.4f}\")"
      ],
      "metadata": {
        "id": "cV0R5y8IbME2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}