{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaanchhitbaranwal-ux/vaanchhit/blob/main/Simple_RAG_Model_With_Sources_Simple_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from rag.data_helper import PDFReader\n",
        "from rag.llm import OllamaLLM\n",
        "from rag.pipeline import Answer, SimpleRAGPipeline\n",
        "from rag.rerank import CrossEncoderRerank\n",
        "from rag.retrieval import BM25Retrieval\n",
        "from rag.text_utils import text2chunk\n",
        "\n",
        "# Set your PDF path here\n",
        "sample_pdf = os.path.join(os.path.dirname(__file__), \"sample.pdf\")\n",
        "contents = PDFReader(pdf_paths=[sample_pdf]).read()\n",
        "text = \" \".join(contents)\n",
        "chunks = text2chunk(text, chunk_size=200, overlap=50)\n",
        "print(f\"Number of chunks: {len(chunks)}\")\n",
        "\n",
        "retrieval = BM25Retrieval(documents=chunks)\n",
        "llm = OllamaLLM(model_name=\"llama3:instruct\")\n",
        "rerank = CrossEncoderRerank(model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "pipeline = SimpleRAGPipeline(retrieval=retrieval, llm=llm, rerank=rerank)\n",
        "\n",
        "\n",
        "def run(query: str) -> Answer:\n",
        "    return pipeline.run(query)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    query = \"What can Ollama do?\"\n",
        "    print(\"Sample query:\", query)\n",
        "    response: Answer = pipeline.run(query)\n",
        "    print(response.answer)\n",
        "    print(\"Now, please ask your own questions!\")\n",
        "    while True:\n",
        "        query = input(\"Your question: \")\n",
        "        response: Answer = run(query)\n",
        "        print(response.answer)\n",
        "        print()"
      ],
      "metadata": {
        "id": "4h39lydHonjJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}