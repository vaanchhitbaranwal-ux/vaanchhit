{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaanchhitbaranwal-ux/vaanchhit/blob/main/Realtime_hacker_news_analisys_agent_news_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import asyncio\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import pytz\n",
        "import json\n",
        "from datetime import datetime\n",
        "from langchain_core.messages.tool import ToolMessage\n",
        "from langchain_core.messages.ai import AIMessage\n",
        "from langchain_core.messages.human import HumanMessage\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langchain.chat_models import init_chat_model\n",
        "from typing import List, Any, Dict\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "from rich.align import Align\n",
        "from rich.progress import Progress, SpinnerColumn, TextColumn\n",
        "from rich.text import Text\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize console\n",
        "console = Console()\n",
        "\n",
        "# Initialize time\n",
        "kst = pytz.timezone('Asia/Seoul')\n",
        "time_now = datetime.now(kst)\n",
        "time_now_str = time_now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "class NewsAgentState(MessagesState):\n",
        "    articles: List[Dict[str, Any]]\n",
        "\n",
        "async def main():\n",
        "\n",
        "    # Header\n",
        "    console.print(Panel.fit(\n",
        "        \"[bold blue]üöÄ AI News Search with LangGraph & FastMCP[/bold blue]\\n\"\n",
        "        \"[dim]Powered by Google RSS and OpenAI GPT-4o-mini[/dim]\\n\"\n",
        "        f\"[dim]Started at: {time_now_str}[/dim]\",\n",
        "        border_style=\"blue\"\n",
        "    ))\n",
        "\n",
        "    # Initialize model\n",
        "    console.print(Panel(\n",
        "        \"[bold yellow]ü§ñ Initializing OpenAI GPT-4o-mini model...[/bold yellow]\",\n",
        "        border_style=\"yellow\"\n",
        "    ))\n",
        "    model = init_chat_model(\"openai:gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\", \"\"))\n",
        "    console.print(Panel(\n",
        "        \"[bold green]‚úÖ Model initialized successfully![/bold green]\",\n",
        "        border_style=\"green\"\n",
        "    ))\n",
        "\n",
        "    # Initialize MCP client\n",
        "    console.print(Panel(\n",
        "        \"[bold yellow]üì° Connecting to Google RSS FastMCP server...[/bold yellow]\",\n",
        "        border_style=\"yellow\"\n",
        "    ))\n",
        "\n",
        "    client = MultiServerMCPClient(\n",
        "        {\n",
        "            \"google-rss-mcp\": {\n",
        "                \"command\": \"python\",\n",
        "                \"args\": [\"./src/modules/mcp_servers/server.py\"],\n",
        "                \"transport\": \"stdio\",\n",
        "            },\n",
        "        }\n",
        "    )\n",
        "    tools = await client.get_tools()\n",
        "\n",
        "    console.print(Panel(\n",
        "        \"[bold green]‚úÖ FastMCP server connected successfully![/bold green]\",\n",
        "        border_style=\"green\"\n",
        "    ))\n",
        "\n",
        "    # Display available tools\n",
        "    tools_table = Table(title=\"üîß Available Google News RSS FastMCP Tools\",\n",
        "                        show_header=True, header_style=\"bold white\")\n",
        "    tools_table.add_column(\"Tool Name\", style=\"cyan\", no_wrap=True)\n",
        "    tools_table.add_column(\"Description\", style=\"white\")\n",
        "\n",
        "    for tool in tools:\n",
        "        tools_table.add_row(tool.name, tool.description)\n",
        "\n",
        "    console.print(tools_table)\n",
        "\n",
        "    # Build LangGraph\n",
        "    console.print(Panel(\n",
        "        \"[bold yellow]üî® Building LangGraph workflow...[/bold yellow]\",\n",
        "        border_style=\"yellow\"\n",
        "    ))\n",
        "\n",
        "    def call_model(state: NewsAgentState):\n",
        "        response = model.bind_tools(tools).invoke(state[\"messages\"])\n",
        "        return {\"messages\": response}\n",
        "\n",
        "    async def summary_node(state: NewsAgentState):\n",
        "        # Extract article data from ToolMessage\n",
        "        articles = []\n",
        "        for msg in state.get(\"messages\", []):\n",
        "            if isinstance(msg, ToolMessage):\n",
        "                try:\n",
        "                    data = json.loads(msg.content)\n",
        "                    if isinstance(data, list):\n",
        "                        articles.extend(data)\n",
        "                except Exception as e:\n",
        "                    console.print(f\"[red]ToolMessage JSON decode error: {e}[/red]\")\n",
        "\n",
        "        # Extract user's question\n",
        "        user_query = None\n",
        "        for msg in state.get(\"messages\", []):\n",
        "            if isinstance(msg, HumanMessage):\n",
        "                user_query = msg.content\n",
        "                break\n",
        "        if not user_query:\n",
        "            user_query = \"No user question provided. Please summarize the article content in 5 sentences or less based on the article title.\"\n",
        "\n",
        "        # Generate summary with progress\n",
        "        console.print(Panel(\n",
        "            f\"[bold yellow]ü§ñ Generating AI summaries for {len(articles)} articles...[/bold yellow]\",\n",
        "            border_style=\"yellow\"\n",
        "        ))\n",
        "\n",
        "        # Create tasks for parallel processing\n",
        "        async def process_single_summary(article, idx):\n",
        "            content = article.get(\"article_content\", \"\")\n",
        "            title = article.get(\"article_title\", \"\")\n",
        "            prompt = [\n",
        "                SystemMessage(content=\"You are a news summarization expert. Please summarize the article content in 5 sentences or less based on the user's question and article title.\"),\n",
        "                HumanMessage(content=f\"Question: {user_query}\\nArticle Title: {title}\\nArticle Content: {content}\\nSummary:\")\n",
        "            ]\n",
        "            try:\n",
        "                summary = await model.ainvoke(prompt)\n",
        "                article[\"summary\"] = summary.content.strip()\n",
        "                console.print(f\"[green]   ‚úì Article {idx+1}: {title[:60]}...[/green]\")\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                console.print(f\"[red]   ‚úó Summary generation failed for article {idx+1}: {e}[/red]\")\n",
        "                article[\"summary\"] = \"Summary generation failed\"\n",
        "                return False\n",
        "\n",
        "        # Execute all summary tasks in parallel\n",
        "        tasks = []\n",
        "        for idx, article in enumerate(articles):\n",
        "            task = asyncio.create_task(process_single_summary(article, idx))\n",
        "            tasks.append(task)\n",
        "\n",
        "        # Wait for all tasks to complete\n",
        "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "        # Count successful summaries\n",
        "        summary_success_count = sum(1 for result in results if result is True)\n",
        "\n",
        "        state[\"articles\"] = articles\n",
        "        console.print(Panel(\n",
        "            f\"[bold green]‚úÖ AI summary generation completed: {summary_success_count}/{len(articles)} articles[/bold green]\",\n",
        "            border_style=\"green\"\n",
        "        ))\n",
        "        return state\n",
        "\n",
        "    def final_answer_node(state: NewsAgentState):\n",
        "        # Get summary list\n",
        "        articles = state.get(\"articles\", [])\n",
        "        summaries = [f\"- {a.get('summary', '')}\" for a in articles if a.get('summary', '') and a.get('summary', '') != \"Summary generation failed\"]\n",
        "        summary_text = \"\\n\".join(summaries)\n",
        "\n",
        "        # Extract user's question\n",
        "        user_query = None\n",
        "        for msg in state.get(\"messages\", []):\n",
        "            if isinstance(msg, HumanMessage):\n",
        "                user_query = msg.content\n",
        "                break\n",
        "        if not user_query:\n",
        "            user_query = \"No user question provided.\"\n",
        "\n",
        "        # Prompt (customize as desired)\n",
        "        prompt = [\n",
        "            SystemMessage(content=\"Below are summaries of multiple news articles. Please provide a comprehensive summary based on the user's question.\"),\n",
        "            HumanMessage(content=f\"Question: {user_query}\\nArticle Summaries:\\n{summary_text}\\nFinal Summary:\")\n",
        "        ]\n",
        "        response = model.invoke(prompt)\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "    builder = StateGraph(NewsAgentState)\n",
        "    builder.add_node(\"call_model\", call_model)\n",
        "    builder.add_node(\"tools\", ToolNode(tools))\n",
        "    builder.add_node(\"summary_node\", summary_node)\n",
        "    builder.add_node(\"final_answer_node\", final_answer_node)\n",
        "    builder.add_edge(START, \"call_model\")\n",
        "    builder.add_conditional_edges(\"call_model\",tools_condition)\n",
        "    builder.add_edge(\"tools\", \"summary_node\")\n",
        "    builder.add_edge(\"summary_node\", \"final_answer_node\")\n",
        "    builder.add_edge(\"final_answer_node\", END)\n",
        "    graph = builder.compile()\n",
        "\n",
        "    console.print(Panel(\n",
        "        \"[bold green]‚úÖ LangGraph workflow built successfully![/bold green]\",\n",
        "        border_style=\"green\"\n",
        "    ))\n",
        "\n",
        "    question = \"Find 16 latest AI-related news articles\"\n",
        "    console.print(Panel(\n",
        "        f\"[bold pink1]üîç QUESTION: {question}[/bold pink1]\",\n",
        "        border_style=\"pink1\",\n",
        "        padding=(1, 2)\n",
        "    ))\n",
        "\n",
        "    console.print(Panel(\n",
        "        \"[bold yellow]üöÄ Running LangGraph workflow...[/bold yellow]\",\n",
        "        border_style=\"yellow\"\n",
        "    ))\n",
        "\n",
        "    try:\n",
        "        response = await graph.ainvoke({\"messages\": question})\n",
        "\n",
        "        # Display results\n",
        "        messages = response[\"messages\"]\n",
        "        if messages and hasattr(messages[-1], 'content') and messages[-1].content:\n",
        "            result_content = messages[-1].content\n",
        "\n",
        "            # Create a beautiful result display\n",
        "            console.print(Panel(\n",
        "                result_content,\n",
        "                title=\"[bold magenta]üìã AI News Summary[/bold magenta]\",\n",
        "                border_style=\"magenta\",\n",
        "                padding=(1, 2)\n",
        "            ))\n",
        "        else:\n",
        "            console.print(Panel(\n",
        "                \"[bold red]‚ùå No response found[/bold red]\",\n",
        "                border_style=\"red\"\n",
        "            ))\n",
        "\n",
        "    except Exception as e:\n",
        "        console.print(Panel(\n",
        "            f\"[bold red]‚ùå Error during search: {str(e)}[/bold red]\",\n",
        "            border_style=\"red\"\n",
        "        ))\n",
        "\n",
        "    # Footer\n",
        "    console.print(Panel(\n",
        "        \"[dim]üéâ All questions completed successfully![/dim]\",\n",
        "        border_style=\"dim\"\n",
        "    ))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ],
      "metadata": {
        "id": "Y2uPHYnqrz1G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}